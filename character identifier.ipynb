{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "'matplotlib' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import LSTM, GRU, Dense, GlobalMaxPool1D, Embedding, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import text, sequence\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "!matplotlib inline\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes=pd.read_csv('episodes_cleaned.csv',index_col='Unnamed: 0')\n",
    "scripts=pd.read_csv('scripts_cleaned.csv',index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dialogue</th>\n",
       "      <th>character_stripped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54585</th>\n",
       "      <td>cause you only get one call. the prison call i...</td>\n",
       "      <td>elaine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54587</th>\n",
       "      <td>i got it - it's out! how about that, huh? oh, ...</td>\n",
       "      <td>kramer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54589</th>\n",
       "      <td>really?</td>\n",
       "      <td>george</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54591</th>\n",
       "      <td>haven't we had this conversation before?</td>\n",
       "      <td>george</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54593</th>\n",
       "      <td>i think we have.</td>\n",
       "      <td>george</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Dialogue character_stripped\n",
       "54585  cause you only get one call. the prison call i...             elaine\n",
       "54587  i got it - it's out! how about that, huh? oh, ...             kramer\n",
       "54589                                            really?             george\n",
       "54591           haven't we had this conversation before?             george\n",
       "54593                                   i think we have.             george"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gek_dial_df=scripts[(scripts['character_stripped']=='george')|(scripts['character_stripped']=='kramer')|(scripts['character_stripped']=='elaine')]\n",
    "gek_dial_df=gek_dial_df[['Dialogue','character_stripped']]\n",
    "gek_dial_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies=pd.get_dummies(gek_dial_df.character_stripped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       ...,\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       ...,\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=dummies.values\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,   42,    2,  266],\n",
       "       [   0,    0,    0, ..., 2289,    3, 2070],\n",
       "       [   0,    0,    0, ...,   46,   14,  100],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,    0,    0,   68],\n",
       "       [   0,    0,    0, ...,   14,  607,  280],\n",
       "       [   0,    0,    0, ...,   56,   48,   29]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = text.Tokenizer(num_words=14000)\n",
    "tokenizer.fit_on_texts(list(gek_dial_df.Dialogue.values))\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(gek_dial_df.Dialogue.values)\n",
    "X_t = sequence.pad_sequences(list_tokenized_train,maxlen=100)\n",
    "X_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = Sequential()\n",
    "lstm_model.add(Embedding(14000,128))\n",
    "lstm_model.add(LSTM(50, return_sequences=True))\n",
    "lstm_model.add(GlobalMaxPool1D())\n",
    "lstm_model.add(Dense(512 ))\n",
    "lstm_model.add(Activation('relu'))\n",
    "lstm_model.add(Dropout(0.5))\n",
    "lstm_model.add(Dense(256 ))\n",
    "lstm_model.add(Activation('relu'))\n",
    "lstm_model.add(Dropout(0.5))\n",
    "lstm_model.add(Dense(128, ))\n",
    "lstm_model.add(Activation('relu'))\n",
    "lstm_model.add(Dropout(0.5))\n",
    "lstm_model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_15 (Embedding)     (None, None, 128)         1792000   \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, None, 50)          35800     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_11 (Glo (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 512)               26112     \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 2,018,523\n",
      "Trainable params: 2,018,523\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22134 samples, validate on 2460 samples\n",
      "Epoch 1/60\n",
      "22134/22134 [==============================] - 17s 786us/step - loss: 0.7518 - acc: 0.6575 - val_loss: 1.2062 - val_acc: 0.4573\n",
      "Epoch 2/60\n",
      "22134/22134 [==============================] - 17s 747us/step - loss: 0.6774 - acc: 0.6946 - val_loss: 1.3166 - val_acc: 0.4508\n",
      "Epoch 3/60\n",
      "22134/22134 [==============================] - 17s 777us/step - loss: 0.6154 - acc: 0.7246 - val_loss: 1.4479 - val_acc: 0.4439\n",
      "Epoch 4/60\n",
      "22134/22134 [==============================] - 18s 819us/step - loss: 0.5586 - acc: 0.7465 - val_loss: 1.6756 - val_acc: 0.4431\n",
      "Epoch 5/60\n",
      "22134/22134 [==============================] - 18s 819us/step - loss: 0.5093 - acc: 0.7643 - val_loss: 1.8373 - val_acc: 0.4419\n",
      "Epoch 6/60\n",
      "22134/22134 [==============================] - 19s 870us/step - loss: 0.4720 - acc: 0.7821 - val_loss: 1.9939 - val_acc: 0.4366\n",
      "Epoch 7/60\n",
      "22134/22134 [==============================] - 18s 803us/step - loss: 0.4379 - acc: 0.7980 - val_loss: 2.1692 - val_acc: 0.4350\n",
      "Epoch 8/60\n",
      "22134/22134 [==============================] - 19s 856us/step - loss: 0.4212 - acc: 0.8066 - val_loss: 2.3522 - val_acc: 0.4341\n",
      "Epoch 9/60\n",
      "22134/22134 [==============================] - 19s 867us/step - loss: 0.3896 - acc: 0.8179 - val_loss: 2.4936 - val_acc: 0.4293\n",
      "Epoch 10/60\n",
      "22134/22134 [==============================] - 18s 816us/step - loss: 0.3724 - acc: 0.8269 - val_loss: 2.6185 - val_acc: 0.4285\n",
      "Epoch 11/60\n",
      "22134/22134 [==============================] - 17s 785us/step - loss: 0.3541 - acc: 0.8341 - val_loss: 2.8716 - val_acc: 0.4402\n",
      "Epoch 12/60\n",
      "22134/22134 [==============================] - 17s 783us/step - loss: 0.3387 - acc: 0.8437 - val_loss: 3.0675 - val_acc: 0.4407\n",
      "Epoch 13/60\n",
      "22134/22134 [==============================] - 18s 791us/step - loss: 0.3245 - acc: 0.8527 - val_loss: 3.0990 - val_acc: 0.4411\n",
      "Epoch 14/60\n",
      "22134/22134 [==============================] - 18s 820us/step - loss: 0.3124 - acc: 0.8568 - val_loss: 3.0228 - val_acc: 0.4260\n",
      "Epoch 15/60\n",
      "22134/22134 [==============================] - 18s 800us/step - loss: 0.3011 - acc: 0.8622 - val_loss: 3.3795 - val_acc: 0.4419\n",
      "Epoch 16/60\n",
      "22134/22134 [==============================] - 18s 796us/step - loss: 0.2919 - acc: 0.8639 - val_loss: 3.5480 - val_acc: 0.4240\n",
      "Epoch 17/60\n",
      "22134/22134 [==============================] - 17s 786us/step - loss: 0.2929 - acc: 0.8658 - val_loss: 3.4036 - val_acc: 0.4280\n",
      "Epoch 18/60\n",
      "22134/22134 [==============================] - 18s 799us/step - loss: 0.2670 - acc: 0.8760 - val_loss: 3.7427 - val_acc: 0.4305\n",
      "Epoch 19/60\n",
      "22134/22134 [==============================] - 17s 789us/step - loss: 0.2665 - acc: 0.8791 - val_loss: 3.6156 - val_acc: 0.4329\n",
      "Epoch 20/60\n",
      "22134/22134 [==============================] - 18s 797us/step - loss: 0.2539 - acc: 0.8813 - val_loss: 3.9850 - val_acc: 0.4236\n",
      "Epoch 21/60\n",
      "22134/22134 [==============================] - 18s 812us/step - loss: 0.2495 - acc: 0.8857 - val_loss: 3.9001 - val_acc: 0.4272\n",
      "Epoch 22/60\n",
      "22134/22134 [==============================] - 18s 804us/step - loss: 0.2429 - acc: 0.8880 - val_loss: 3.9537 - val_acc: 0.4313\n",
      "Epoch 23/60\n",
      "22134/22134 [==============================] - 18s 818us/step - loss: 0.2389 - acc: 0.8882 - val_loss: 3.9888 - val_acc: 0.4337\n",
      "Epoch 24/60\n",
      "22134/22134 [==============================] - 18s 811us/step - loss: 0.2332 - acc: 0.8932 - val_loss: 4.0539 - val_acc: 0.4297\n",
      "Epoch 25/60\n",
      "22134/22134 [==============================] - 18s 798us/step - loss: 0.2187 - acc: 0.8961 - val_loss: 4.3381 - val_acc: 0.4285\n",
      "Epoch 26/60\n",
      "22134/22134 [==============================] - 18s 800us/step - loss: 0.2263 - acc: 0.8962 - val_loss: 4.3260 - val_acc: 0.4390\n",
      "Epoch 27/60\n",
      "22134/22134 [==============================] - 18s 806us/step - loss: 0.2277 - acc: 0.8955 - val_loss: 4.1501 - val_acc: 0.4260\n",
      "Epoch 28/60\n",
      "22134/22134 [==============================] - 18s 796us/step - loss: 0.2149 - acc: 0.9008 - val_loss: 4.2665 - val_acc: 0.4305\n",
      "Epoch 29/60\n",
      "22134/22134 [==============================] - 18s 813us/step - loss: 0.2085 - acc: 0.9029 - val_loss: 4.5368 - val_acc: 0.4285\n",
      "Epoch 30/60\n",
      "22134/22134 [==============================] - 18s 809us/step - loss: 0.2048 - acc: 0.9029 - val_loss: 4.4920 - val_acc: 0.4276\n",
      "Epoch 31/60\n",
      "22134/22134 [==============================] - 18s 804us/step - loss: 0.1989 - acc: 0.9073 - val_loss: 4.5799 - val_acc: 0.4272\n",
      "Epoch 32/60\n",
      "22134/22134 [==============================] - 18s 808us/step - loss: 0.1997 - acc: 0.9067 - val_loss: 4.6765 - val_acc: 0.4167\n",
      "Epoch 33/60\n",
      "22134/22134 [==============================] - 18s 813us/step - loss: 0.1952 - acc: 0.9068 - val_loss: 4.6259 - val_acc: 0.4289\n",
      "Epoch 34/60\n",
      "22134/22134 [==============================] - 18s 805us/step - loss: 0.1931 - acc: 0.9085 - val_loss: 4.7168 - val_acc: 0.4138\n",
      "Epoch 35/60\n",
      "22134/22134 [==============================] - 18s 807us/step - loss: 0.1903 - acc: 0.9106 - val_loss: 4.6675 - val_acc: 0.4313\n",
      "Epoch 36/60\n",
      "22134/22134 [==============================] - 18s 796us/step - loss: 0.1905 - acc: 0.9100 - val_loss: 4.5814 - val_acc: 0.4240\n",
      "Epoch 37/60\n",
      "22134/22134 [==============================] - 18s 795us/step - loss: 0.1873 - acc: 0.9128 - val_loss: 4.7174 - val_acc: 0.4309\n",
      "Epoch 38/60\n",
      "22134/22134 [==============================] - 18s 796us/step - loss: 0.1824 - acc: 0.9147 - val_loss: 4.6863 - val_acc: 0.4313\n",
      "Epoch 39/60\n",
      "22134/22134 [==============================] - 18s 792us/step - loss: 0.1816 - acc: 0.9153 - val_loss: 4.8291 - val_acc: 0.4309\n",
      "Epoch 40/60\n",
      "22134/22134 [==============================] - 18s 799us/step - loss: 0.1773 - acc: 0.9171 - val_loss: 4.8725 - val_acc: 0.4236\n",
      "Epoch 41/60\n",
      "22134/22134 [==============================] - 17s 787us/step - loss: 0.1758 - acc: 0.9167 - val_loss: 4.9683 - val_acc: 0.4289\n",
      "Epoch 42/60\n",
      "22134/22134 [==============================] - 17s 790us/step - loss: 0.1772 - acc: 0.9166 - val_loss: 4.9090 - val_acc: 0.4272\n",
      "Epoch 43/60\n",
      "22134/22134 [==============================] - 18s 792us/step - loss: 0.1760 - acc: 0.9175 - val_loss: 4.9516 - val_acc: 0.4244\n",
      "Epoch 44/60\n",
      "22134/22134 [==============================] - 18s 795us/step - loss: 0.1710 - acc: 0.9202 - val_loss: 4.9144 - val_acc: 0.4187\n",
      "Epoch 45/60\n",
      "22134/22134 [==============================] - 17s 791us/step - loss: 0.1734 - acc: 0.9175 - val_loss: 4.8874 - val_acc: 0.4293\n",
      "Epoch 46/60\n",
      "22134/22134 [==============================] - 17s 790us/step - loss: 0.1675 - acc: 0.9181 - val_loss: 5.1704 - val_acc: 0.4252\n",
      "Epoch 47/60\n",
      "22134/22134 [==============================] - 18s 795us/step - loss: 0.1656 - acc: 0.9209 - val_loss: 5.3622 - val_acc: 0.4297\n",
      "Epoch 48/60\n",
      "22134/22134 [==============================] - 19s 848us/step - loss: 0.1631 - acc: 0.9225 - val_loss: 5.2435 - val_acc: 0.4325\n",
      "Epoch 49/60\n",
      "22134/22134 [==============================] - 18s 834us/step - loss: 0.1744 - acc: 0.9193 - val_loss: 4.9813 - val_acc: 0.4321\n",
      "Epoch 50/60\n",
      "22134/22134 [==============================] - 18s 814us/step - loss: 0.1650 - acc: 0.9221 - val_loss: 5.1671 - val_acc: 0.4329\n",
      "Epoch 51/60\n",
      "22134/22134 [==============================] - 18s 807us/step - loss: 0.1649 - acc: 0.9221 - val_loss: 5.0205 - val_acc: 0.4268\n",
      "Epoch 52/60\n",
      "22134/22134 [==============================] - 18s 813us/step - loss: 0.1652 - acc: 0.9208 - val_loss: 5.1647 - val_acc: 0.4358\n",
      "Epoch 53/60\n",
      "22134/22134 [==============================] - 18s 798us/step - loss: 0.1595 - acc: 0.9235 - val_loss: 5.2164 - val_acc: 0.4382\n",
      "Epoch 54/60\n",
      "22134/22134 [==============================] - 18s 796us/step - loss: 0.1600 - acc: 0.9233 - val_loss: 5.1576 - val_acc: 0.4354\n",
      "Epoch 55/60\n",
      "22134/22134 [==============================] - 17s 788us/step - loss: 0.1537 - acc: 0.9258 - val_loss: 5.4236 - val_acc: 0.4354\n",
      "Epoch 56/60\n",
      "22134/22134 [==============================] - 18s 792us/step - loss: 0.1579 - acc: 0.9237 - val_loss: 5.3701 - val_acc: 0.4354\n",
      "Epoch 57/60\n",
      "22134/22134 [==============================] - 18s 808us/step - loss: 0.1551 - acc: 0.9248 - val_loss: 5.4327 - val_acc: 0.4272\n",
      "Epoch 58/60\n",
      "22134/22134 [==============================] - 18s 799us/step - loss: 0.1496 - acc: 0.9288 - val_loss: 5.5695 - val_acc: 0.4362\n",
      "Epoch 59/60\n",
      "22134/22134 [==============================] - 17s 784us/step - loss: 0.1619 - acc: 0.9225 - val_loss: 5.1786 - val_acc: 0.4289\n",
      "Epoch 60/60\n",
      "22134/22134 [==============================] - 17s 782us/step - loss: 0.1579 - acc: 0.9264 - val_loss: 5.1984 - val_acc: 0.4260\n"
     ]
    }
   ],
   "source": [
    "lstm_history=lstm_model.fit(X_t,\n",
    "                labels,\n",
    "                epochs=60,\n",
    "                batch_size=256,\n",
    "                validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected activation_46 to have 3 dimensions, but got array with shape (24594, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-109-dc9f9f715ac8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mActivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\learn-env\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    948\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 950\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m    951\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\learn-env\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    785\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m                 exception_prefix='target')\n\u001b[0m\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m             \u001b[1;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\learn-env\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    125\u001b[0m                         \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    128\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking target: expected activation_46 to have 3 dimensions, but got array with shape (24594, 3)"
     ]
    }
   ],
   "source": [
    "from keras.layers import Activation \n",
    "num_words=14000\n",
    "num_classes = 2\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(14000,128))\n",
    "model.add(Dense(512 ))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256 ))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, ))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_t, labels, epochs=60, batch_size=256,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_16 (Embedding)     (None, None, 128)         1792000   \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, None, 512)         66048     \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, None, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, None, 512)         0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, None, 256)         131328    \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, None, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, None, 256)         0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, None, 128)         32896     \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, None, 3)           387       \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, None, 3)           0         \n",
      "=================================================================\n",
      "Total params: 2,022,659\n",
      "Trainable params: 2,022,659\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24594, 100)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
